# LSTM + Luong Attention configuration

model:
  name: "lstm_luong"
  embed_dim: 512
  hidden_dim: 512
  # For LSTM encoder/decoder; keep num_layers for backward compatibility
  num_layers: 3
  encoder_layers: 3
  decoder_layers: 3
  dropout: 0.1
  attention_type: "general"  # Luong attention types: general, dot, concat

training:
  batch_size: 16
  num_epochs: 10
  learning_rate: 0.001
  optimizer: "adam"
  scheduler: "cosine"
  clip_grad_norm: 5.0
  warmup_steps: null
  eval_every: 1000
  save_every: 5000

data:
  # Special token IDs
  sos_id: 1
  eos_id: 2
  pad_id: 0
  unk_id: 3
  
  # Target level: 'word' or 'phoneme'
  target_level: "phoneme"
  source_level: "phoneme"
  
  ## Direct paths to training data files
  train_src: "dataset/train_end_clean.en"
  train_tgt: "dataset/train_end_clean.vi"
  
  # Direct paths to dev data files
  dev_src: "dataset/dev_end_clean.en"
  dev_tgt: "dataset/dev_end_clean.vi"
  
  # Direct paths to test data files
  test_src: "dataset/test_end_clean.en"
  test_tgt: "dataset/test_end_clean.vi"
  
  # Direct paths to vocabulary JSON files (for phoneme-level)
  vocab_json_train: "dataset/full_vocab.json"
  vocab_json_dev: "dataset/full_vocab.json"
  vocab_json_test: "dataset/full_vocab.json"
  
  # Vocabulary settings
  min_count: 3
  max_seq_len: 100

device: "cuda"
seed: 42